## Домашняя работа #4
# License Plate Recognition
### Студент : Дмитрий Клёстов

В задании требуется решить задачу распознавания текста на изображениях регистрационных знаков

### 1. EDA

Для начала нужно посмотреть на данные. Они состоят из тренировочного и тестового наборов.

В тренировочном наборе данные разделены на две части: simple и complex и представляют собой изображения
регистрационных знаков (вырезанных из изображений с автомобилями) в виде файлов с именами соответствующими расшифровке знака.

simple - изображения с выровненными знаками

complex - произвольно расположенные изображения знаков

В тестовом наборе даны только изображения без соответствующиъ расшифровок

На этом этапе я сделал небольшой анализ "разметки" - построил распределения символов по их позициям.

Также я сделал функцию проверки номера, по входной строке определяющую валидный ли номер с помощью регулярного выражения

$$'^[ABCEHKMOPTXY][0-9]{3}[ABCEHKMOPTXY]{2}[0-9]{2,3}$'$$ - одна буква из возможных, затем 3 цифры, две буквы и 2 или 3 цифры

Этой функцией я проверил все номера в тренировочном наборе - все были без ошибок

### 2. Dataset и обучение

Я использовал подходы по мотивам семинара - модель на основе рекуррентной свёрточной архитектуры и CTCLoss

Я разделил данные на train и val в соотношении 9 к 1 случайным образом (отдельно simple, отдельно complex)

Первый этап тренировки - обучение модели распознаванию текста на simple данных. Это даёт хорошее качество на выровненных номерах, что полезно в дальнейшем

Лучшее среднее расстояние Левенштейна (на валидационном наборе из simple) получилось 0.0737, значение loss-функции - 0.0633

Имея обученную модель, я добавил в архитектуру слой с Spatial Transform Network (STN) и завернул в новую модель, при этом заморозил веса модели распознавания

Дальше я сделал обучение об'единённой модели только на complex данных - так что обучалась только STN

На валидационном наборе (complex) лучшее среднее расстояние Левенштейна - 0.0703, loss - 0.0383

Этот результат я засабмитил в Kaggle, скор - 0.114 на public и 0.112 на private

После этого я разморозил веса и обучил об'единённую модель на simple+complex данных

Это дало расстояние Левенштейна 0.0443 и loss 0.285 на simple+complex валидационном наборе 

В kaggle эта модель предсказала на 0.0395 на public и 0.0447 на private

Все запуски я делал по 100 эпох и выбирал модель с минимальным loss для следующего этапа

### 3. Refine

Дальше я сфокусировался на валидации прогноза с помощью функции из пункта EDA.
Из всех предсказаний модель определила около 50 невалидных номеров (т.е.например недостаточно или избыточно длинных, 
либо с цифрами и буквами не на своих местах). При взгляде на эти номера было видно, что большая их часть действительно выглядит сложно,
есть пара изображений, вырезанных ошибочно (совсем без номера), но также несколько номеров "на глаз" было видно довольно хорошо

Я сделал на этой подвыборке доуточнение следующим способом (независимо):
1. попробовал поменять букву о на цифру 0 и наоборот и поэкспериментировал с другими буквами
2. покрутил сами изображения с шагом 5 градусов и попробовал предсказать той же моделью ещё раз

После этих шагов (в основном после 2го) большая часть предсказаний стала валидной.

Я засабмитил этот результат и получил скор 0.0359 и 0.0461 на public и private соответственно

Из оставшихся 9 примеров 2 были без номера. Остальные 7 я разметил вручную и дозаслал в Kaggle.
Это дало скор 0.0328 на public и 0.0408 на private

Поэтому честный результат без ручной работы 0.0461(0.0359) или 0.0447(0.0395), если бы я выбрал результат без доуточнения.


### 4. Вывод

По заветам с семинара повторил простой подход обучения в несколько этапов:
сначала на выровненных номерах, затем на произвольных с добавлением STN, это дало существенное улучшение распознавания на
тестовых данных. Также модель показала себя хорошо на распознавании на этапе доуточнения, когда ей подавали повёрнутые
номера - справилась с 80% таких данных.